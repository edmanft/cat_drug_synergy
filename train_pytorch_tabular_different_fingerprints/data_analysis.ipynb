{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>32</th>\n",
       "      <th>64</th>\n",
       "      <th>128</th>\n",
       "      <th>256</th>\n",
       "      <th>512</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CategoryEmbedding</td>\n",
       "      <td>0.184725</td>\n",
       "      <td>0.177091</td>\n",
       "      <td>0.148471</td>\n",
       "      <td>0.161178</td>\n",
       "      <td>0.193829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AutoInt</td>\n",
       "      <td>0.258447</td>\n",
       "      <td>0.274583</td>\n",
       "      <td>0.266002</td>\n",
       "      <td>0.281492</td>\n",
       "      <td>0.276155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TabTransformer</td>\n",
       "      <td>0.210695</td>\n",
       "      <td>0.239527</td>\n",
       "      <td>0.202102</td>\n",
       "      <td>0.167703</td>\n",
       "      <td>0.148261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model        32        64       128       256       512\n",
       "0  CategoryEmbedding  0.184725  0.177091  0.148471  0.161178  0.193829\n",
       "1            AutoInt  0.258447  0.274583  0.266002  0.281492  0.276155\n",
       "2     TabTransformer  0.210695  0.239527  0.202102  0.167703  0.148261"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob('*.csv')\n",
    "# Create global pandas table with batchsize and model for each fingerprint size\n",
    "# No fingeprint\n",
    "\n",
    "no_fp = pd.DataFrame(columns=['Model', 32, 64, 128, 256, 512])\n",
    "no_fp['Model'] = ['CategoryEmbedding', 'AutoInt', 'TabTransformer']\n",
    "for batch_size in [32, 64, 128, 256, 512]:\n",
    "    path = f'./pytorch_tabular_no_fp_batch_{batch_size}_seed_0.csv'\n",
    "    df = pd.read_csv(path)\n",
    "    # Check the model_names\n",
    "    model_names = list(df['Model']) \n",
    "    wpc = list(df['LB WPC'])\n",
    "    # Add the WPC for each model, if the model does not exist, add -\n",
    "    for i, model in enumerate(no_fp['Model']):\n",
    "        if model in model_names:\n",
    "            no_fp.loc[i, batch_size] = wpc[model_names.index(model)]\n",
    "        else:\n",
    "            no_fp.loc[i, batch_size] = '-'\n",
    "\n",
    "     \n",
    "\n",
    "no_fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>32</th>\n",
       "      <th>64</th>\n",
       "      <th>128</th>\n",
       "      <th>256</th>\n",
       "      <th>512</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CategoryEmbedding</td>\n",
       "      <td>0.206052</td>\n",
       "      <td>0.184729</td>\n",
       "      <td>0.164263</td>\n",
       "      <td>0.151062</td>\n",
       "      <td>0.119197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AutoInt</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TabTransformer</td>\n",
       "      <td>0.22761</td>\n",
       "      <td>0.174891</td>\n",
       "      <td>0.14291</td>\n",
       "      <td>0.208954</td>\n",
       "      <td>0.19893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model        32        64       128       256       512\n",
       "0  CategoryEmbedding  0.206052  0.184729  0.164263  0.151062  0.119197\n",
       "1            AutoInt         -         -         -         -         -\n",
       "2     TabTransformer   0.22761  0.174891   0.14291  0.208954   0.19893"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob('*.csv')\n",
    "# Create global pandas table with batchsize and model for each fingerprint size\n",
    "# No fingeprint\n",
    "\n",
    "fp_1024 = pd.DataFrame(columns=['Model', 32, 64, 128, 256, 512])\n",
    "fp_1024['Model'] = ['CategoryEmbedding', 'AutoInt', 'TabTransformer']\n",
    "for batch_size in [32, 64, 128, 256, 512]:\n",
    "    path = f'./pytorch_tabular_fp_1024_batch_{batch_size}_seed_0.csv'\n",
    "    df = pd.read_csv(path)\n",
    "    # Check the model_names\n",
    "    model_names = list(df['Model']) \n",
    "    wpc = list(df['LB WPC'])\n",
    "    # Add the WPC for each model, if the model does not exist, add -\n",
    "    for i, model in enumerate(no_fp['Model']):\n",
    "        if model in model_names:\n",
    "            fp_1024.loc[i, batch_size] = wpc[model_names.index(model)]\n",
    "        else:\n",
    "            fp_1024.loc[i, batch_size] = '-'\n",
    "\n",
    "     \n",
    "\n",
    "fp_1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>32</th>\n",
       "      <th>64</th>\n",
       "      <th>128</th>\n",
       "      <th>256</th>\n",
       "      <th>512</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CategoryEmbedding</td>\n",
       "      <td>0.206052</td>\n",
       "      <td>0.184729</td>\n",
       "      <td>0.164263</td>\n",
       "      <td>0.151062</td>\n",
       "      <td>0.119197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AutoInt</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TabTransformer</td>\n",
       "      <td>0.22761</td>\n",
       "      <td>0.174891</td>\n",
       "      <td>0.14291</td>\n",
       "      <td>0.208954</td>\n",
       "      <td>0.19893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model        32        64       128       256       512\n",
       "0  CategoryEmbedding  0.206052  0.184729  0.164263  0.151062  0.119197\n",
       "1            AutoInt         -         -         -         -         -\n",
       "2     TabTransformer   0.22761  0.174891   0.14291  0.208954   0.19893"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = glob.glob('*.csv')\n",
    "# Create global pandas table with batchsize and model for each fingerprint size\n",
    "# No fingeprint\n",
    "\n",
    "fp_2048 = pd.DataFrame(columns=['Model', 32, 64, 128, 256, 512])\n",
    "fp_2048['Model'] = ['CategoryEmbedding', 'AutoInt', 'TabTransformer']\n",
    "for batch_size in [32, 64, 128, 256, 512]:\n",
    "    path = f'./pytorch_tabular_fp_1024_batch_{batch_size}_seed_0.csv'\n",
    "    df = pd.read_csv(path)\n",
    "    # Check the model_names\n",
    "    model_names = list(df['Model']) \n",
    "    wpc = list(df['LB WPC'])\n",
    "    # Add the WPC for each model, if the model does not exist, add -\n",
    "    for i, model in enumerate(no_fp['Model']):\n",
    "        if model in model_names:\n",
    "            fp_2048.loc[i, batch_size] = wpc[model_names.index(model)]\n",
    "        else:\n",
    "            fp_2048.loc[i, batch_size] = '-'\n",
    "\n",
    "     \n",
    "\n",
    "fp_2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "% === CategoryEmbedding ===\n",
      "\\begin{table}\n",
      "\\caption{LB WPC results for CategoryEmbedding across batch sizes and fingerprint settings.}\n",
      "\\label{tab:lbwpc_categoryembedding}\n",
      "\\begin{tabular}{lccccc}\n",
      "\\toprule\n",
      " & 32 & 64 & 128 & 256 & 512 \\\\\n",
      "\\midrule\n",
      "no_fp & 0.185 & 0.177 & 0.148 & 0.161 & \\textbf{0.194} \\\\\n",
      "1024 & \\textbf{0.206} & 0.185 & 0.164 & 0.151 & 0.119 \\\\\n",
      "2048 & 0.022 & \\textbf{0.114} & 0.093 & 0.062 & 0.071 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "% === AutoInt ===\n",
      "\\begin{table}\n",
      "\\caption{LB WPC results for AutoInt across batch sizes and fingerprint settings.}\n",
      "\\label{tab:lbwpc_autoint}\n",
      "\\begin{tabular}{lccccc}\n",
      "\\toprule\n",
      " & 32 & 64 & 128 & 256 & 512 \\\\\n",
      "\\midrule\n",
      "no_fp & 0.258 & 0.275 & 0.266 & \\textbf{0.281} & 0.276 \\\\\n",
      "1024 & - & - & - & - & - \\\\\n",
      "2048 & - & - & - & - & - \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n",
      "\n",
      "% === TabTransformer ===\n",
      "\\begin{table}\n",
      "\\caption{LB WPC results for TabTransformer across batch sizes and fingerprint settings.}\n",
      "\\label{tab:lbwpc_tabtransformer}\n",
      "\\begin{tabular}{lccccc}\n",
      "\\toprule\n",
      " & 32 & 64 & 128 & 256 & 512 \\\\\n",
      "\\midrule\n",
      "no_fp & 0.211 & \\textbf{0.240} & 0.202 & 0.168 & 0.148 \\\\\n",
      "1024 & \\textbf{0.228} & 0.175 & 0.143 & 0.209 & 0.199 \\\\\n",
      "2048 & 0.115 & 0.164 & 0.134 & \\textbf{0.183} & 0.142 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "benchmark_dir = \".\"\n",
    "\n",
    "\n",
    "# Models you're interested in\n",
    "models = ['CategoryEmbedding', 'AutoInt', 'TabTransformer']\n",
    "\n",
    "# Fingerprint types\n",
    "fp_types = {\n",
    "    \"No fingerprints\": \"pytorch_tabular_no_fp_batch_{}_seed_0.csv\",\n",
    "    \"Morgan 1024 bits\":  \"pytorch_tabular_fp_1024_batch_{}_seed_0.csv\",\n",
    "    \"Morgan 2048 bits\":  \"pytorch_tabular_fp_2048_batch_{}_seed_0.csv\"\n",
    "}\n",
    "\n",
    "# Batch sizes to include\n",
    "batch_sizes = [32, 64, 128, 256, 512]\n",
    "\n",
    "# Create a dict to hold DataFrames per model\n",
    "model_tables = {model: pd.DataFrame(index=fp_types.keys(), columns=batch_sizes) for model in models}\n",
    "\n",
    "# Fill the tables\n",
    "for fp_label, file_template in fp_types.items():\n",
    "    for batch_size in batch_sizes:\n",
    "        file = file_template.format(batch_size)\n",
    "        if not os.path.exists(file):\n",
    "            continue\n",
    "        df = pd.read_csv(file)\n",
    "        for model in models:\n",
    "            if model in df['Model'].values:\n",
    "                val = df[df['Model'] == model]['LB WPC'].values[0]\n",
    "                model_tables[model].loc[fp_label, batch_size] = val\n",
    "            else:\n",
    "                model_tables[model].loc[fp_label, batch_size] = '-'\n",
    "\n",
    "# Convert to LaTeX\n",
    "for model, table in model_tables.items():\n",
    "    # Format and bold best per row\n",
    "    for idx, row in table.iterrows():\n",
    "        numeric_row = row.apply(pd.to_numeric, errors='coerce')\n",
    "        if numeric_row.notna().any():\n",
    "            best_col = numeric_row.idxmax()\n",
    "            for col in table.columns:\n",
    "                val = table.loc[idx, col]\n",
    "                if val == '-' or pd.isna(val):\n",
    "                    table.loc[idx, col] = '-'\n",
    "                elif col == best_col:\n",
    "                    table.loc[idx, col] = f\"\\\\textbf{{{float(val):.3f}}}\"\n",
    "                else:\n",
    "                    table.loc[idx, col] = f\"{float(val):.3f}\"\n",
    "        else:\n",
    "            table.loc[idx] = ['-'] * len(table.columns)\n",
    "\n",
    "    print(f\"\\n% === {model} ===\")\n",
    "    print(table.to_latex(\n",
    "        escape=False,\n",
    "        column_format=\"l\" + \"c\" * len(table.columns),\n",
    "        caption=f\"LB WPC results for {model} across batch sizes and fingerprint settings.\",\n",
    "        label=f\"tab:lbwpc_{model.lower()}\"\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ LaTeX file 'lbwpc_tables.tex' created successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "benchmark_dir = \".\"\n",
    "\n",
    "# Models you're interested in\n",
    "models = ['CategoryEmbedding', 'AutoInt', 'TabTransformer']\n",
    "\n",
    "# Fingerprint types\n",
    "fp_types = {\n",
    "    \"No fingerprints\": \"pytorch_tabular_no_fp_batch_{}_seed_0.csv\",\n",
    "    \"Morgan 1024 bits\":  \"pytorch_tabular_fp_1024_batch_{}_seed_0.csv\",\n",
    "    \"Morgan 2048 bits\":  \"pytorch_tabular_fp_2048_batch_{}_seed_0.csv\"\n",
    "}\n",
    "\n",
    "# Batch sizes to include\n",
    "batch_sizes = [32, 64, 128, 256, 512]\n",
    "\n",
    "# Create a dict to hold DataFrames per model\n",
    "model_tables = {model: pd.DataFrame(index=fp_types.keys(), columns=batch_sizes) for model in models}\n",
    "\n",
    "# Fill the tables\n",
    "for fp_label, file_template in fp_types.items():\n",
    "    for batch_size in batch_sizes:\n",
    "        file = file_template.format(batch_size)\n",
    "        path = os.path.join(benchmark_dir, file)\n",
    "        if not os.path.exists(path):\n",
    "            continue\n",
    "        df = pd.read_csv(path)\n",
    "        for model in models:\n",
    "            if model in df['Model'].values:\n",
    "                val = df[df['Model'] == model]['LB WPC'].values[0]\n",
    "                model_tables[model].loc[fp_label, batch_size] = val\n",
    "            else:\n",
    "                model_tables[model].loc[fp_label, batch_size] = '-'\n",
    "\n",
    "# Start writing LaTeX file\n",
    "latex_lines = [r\"\\documentclass{article}\",\n",
    "               r\"\\usepackage{booktabs}\",\n",
    "               r\"\\usepackage[margin=1in]{geometry}\",\n",
    "               r\"\\begin{document}\"]\n",
    "\n",
    "# Generate each model's table\n",
    "for model, table in model_tables.items():\n",
    "    # Format and bold best per row\n",
    "    for idx, row in table.iterrows():\n",
    "        numeric_row = row.apply(pd.to_numeric, errors='coerce')\n",
    "        if numeric_row.notna().any():\n",
    "            best_col = numeric_row.idxmax()\n",
    "            for col in table.columns:\n",
    "                val = table.loc[idx, col]\n",
    "                if val == '-' or pd.isna(val):\n",
    "                    table.loc[idx, col] = '-'\n",
    "                elif col == best_col:\n",
    "                    table.loc[idx, col] = f\"\\\\textbf{{{float(val):.3f}}}\"\n",
    "                else:\n",
    "                    table.loc[idx, col] = f\"{float(val):.3f}\"\n",
    "        else:\n",
    "            table.loc[idx] = ['-'] * len(table.columns)\n",
    "\n",
    "    # Build LaTeX table with extra batch size header\n",
    "    col_format = \"l\" + \"c\" * len(table.columns)\n",
    "    batch_header = \" & \" + \" & \".join(str(b) for b in table.columns) + r\" \\\\\"\n",
    "    midrule = r\"\\cmidrule(lr){2-\" + str(len(table.columns)+1) + \"}\"\n",
    "\n",
    "    latex_lines += [\n",
    "        r\"\\begin{table}[h!]\",\n",
    "        r\"\\centering\",\n",
    "        rf\"\\caption{{LB WPC results for {model} across batch sizes and fingerprint settings.}}\",\n",
    "        rf\"\\label{{tab:lbwpc_{model.lower()}}}\",\n",
    "        rf\"\\begin{{tabular}}{{{col_format}}}\",\n",
    "        r\"\\toprule\",\n",
    "        r\"& \\multicolumn{\" + str(len(table.columns)) + r\"}{c}{Batch size} \\\\\",\n",
    "        midrule,\n",
    "        r\"Fingerprint & \" + \" & \".join(str(b) for b in table.columns) + r\" \\\\\",\n",
    "        r\"\\midrule\"\n",
    "    ]\n",
    "\n",
    "    for idx, row in table.iterrows():\n",
    "        latex_lines.append(f\"{idx} & \" + \" & \".join(str(row[col]) for col in table.columns) + r\" \\\\\")\n",
    "\n",
    "    latex_lines += [\n",
    "        r\"\\bottomrule\",\n",
    "        r\"\\end{tabular}\",\n",
    "        r\"\\end{table}\",\n",
    "        \"\"\n",
    "    ]\n",
    "\n",
    "# Close LaTeX document\n",
    "latex_lines.append(r\"\\end{document}\")\n",
    "\n",
    "# Write to file\n",
    "with open(\"lbwpc_tables.tex\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(latex_lines))\n",
    "\n",
    "print(\"✅ LaTeX file 'lbwpc_tables.tex' created successfully.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cat_drug_synergy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
