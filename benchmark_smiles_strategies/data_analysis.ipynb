{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[ht]\n",
      "\\centering\n",
      "\\footnotesize\n",
      "\\caption{\\textbf{LB WPC comparison with and without Morgan fingerprints using different imputation strategies.} Results are reported as mean (standard deviation) over 10 random seeds.}\n",
      "\\begin{tabular}{lccccccc}\n",
      "\\toprule\n",
      "Model & No FP & Zero-512 & Zero-1024 & Zero-2048 & Drop-512 & Drop-1024 & Drop-2048 \\\\\n",
      "\\midrule\n",
      "Linear & \\textbf{0.268 (0.000)} & 0.254 (0.000) & 0.258 (0.000) & 0.225 (0.000) & 0.259 (0.000) & 0.220 (0.000) & 0.244 (0.000) \\\\\n",
      "Ridge & 0.257 (0.000) & 0.266 (0.000) & 0.266 (0.000) & 0.266 (0.000) & 0.281 (0.000) & 0.281 (0.000) & \\textbf{0.281 (0.000)} \\\\\n",
      "Lasso & 0.099 (0.000) & 0.121 (0.000) & 0.130 (0.000) & 0.127 (0.000) & 0.133 (0.000) & \\textbf{0.156 (0.000)} & 0.156 (0.000) \\\\\n",
      "ElasticNet & 0.113 (0.000) & 0.113 (0.000) & 0.117 (0.000) & 0.117 (0.000) & 0.170 (0.000) & \\textbf{0.183 (0.000)} & 0.182 (0.000) \\\\\n",
      "Bayesian Ridge & \\textbf{0.268 (0.000)} & 0.133 (0.000) & 0.121 (0.000) & 0.116 (0.000) & 0.189 (0.000) & 0.189 (0.000) & 0.188 (0.000) \\\\\n",
      "SGD & \\textbf{0.268 (0.004)} & 0.001 (0.083) & 0.013 (0.072) & -0.008 (0.083) & -0.027 (0.083) & 0.025 (0.093) & -0.045 (0.071) \\\\\n",
      "SVR & \\textbf{0.194 (0.000)} & 0.145 (0.000) & 0.145 (0.000) & 0.134 (0.000) & 0.154 (0.000) & 0.179 (0.000) & 0.180 (0.000) \\\\\n",
      "GP & \\textbf{0.118 (0.000)} & 0.074 (0.000) & 0.074 (0.000) & 0.074 (0.000) & 0.104 (0.000) & 0.104 (0.000) & 0.104 (0.000) \\\\\n",
      "Decision Tree & 0.093 (0.029) & 0.054 (0.018) & 0.075 (0.018) & 0.040 (0.022) & 0.069 (0.028) & \\textbf{0.106 (0.018)} & 0.092 (0.020) \\\\\n",
      "Random Forest & \\textbf{0.256 (0.021)} & 0.227 (0.024) & 0.227 (0.024) & 0.232 (0.017) & 0.219 (0.030) & 0.217 (0.027) & 0.249 (0.030) \\\\\n",
      "Extra Trees & 0.258 (0.011) & 0.206 (0.009) & \\textbf{0.273 (0.023)} & 0.264 (0.011) & 0.168 (0.027) & 0.166 (0.016) & 0.225 (0.014) \\\\\n",
      "AdaBoost & 0.110 (0.018) & 0.089 (0.047) & 0.140 (0.028) & 0.092 (0.032) & 0.150 (0.042) & \\textbf{0.157 (0.065)} & 0.141 (0.029) \\\\\n",
      "Gradient Boosting & \\textbf{0.257 (0.005)} & 0.225 (0.012) & 0.207 (0.006) & 0.199 (0.006) & 0.250 (0.005) & 0.199 (0.009) & 0.221 (0.004) \\\\\n",
      "XGB & \\textbf{0.237 (0.000)} & 0.202 (0.000) & 0.214 (0.000) & 0.165 (0.000) & 0.204 (0.000) & 0.221 (0.000) & 0.176 (0.000) \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define mapping to match acronyms from your LaTeX table\n",
    "model_name_map = {\n",
    "    \"Linear Regression\": \"Linear\",\n",
    "    \"Ridge Regression\": \"Ridge\",\n",
    "    \"Lasso Regression\": \"Lasso\",\n",
    "    \"ElasticNet Regression\": \"ElasticNet\",\n",
    "    \"Bayesian Ridge Regression\": \"Bayesian Ridge\",\n",
    "    \"Stochastic Gradient Descent\": \"SGD\",\n",
    "    \"Support Vector Regression\": \"SVR\",\n",
    "    \"Gaussian Process\": \"GP\",\n",
    "    \"Decision Tree\": \"Decision Tree\",\n",
    "    \"Random Forest\": \"Random Forest\",\n",
    "    \"Extra Trees\": \"Extra Trees\",\n",
    "    \"AdaBoost\": \"AdaBoost\",\n",
    "    \"Gradient Boosting\": \"Gradient Boosting\",\n",
    "    \"XGBRegressor\": \"XGB\",\n",
    "}\n",
    "\n",
    "# Use this to enforce model row order\n",
    "model_order = [\n",
    "    \"Linear\", \"Ridge\", \"Lasso\", \"ElasticNet\", \"Bayesian Ridge\",\n",
    "    \"SGD\", \"SVR\", \"GP\", \"Decision Tree\", \"Random Forest\",\n",
    "    \"Extra Trees\", \"AdaBoost\", \"Gradient Boosting\", \"XGB\"\n",
    "]\n",
    "\n",
    "# Strategy column order\n",
    "strategies = [\"No FP\", \"Zero-512\", \"Zero-1024\", \"Zero-2048\", \"Drop-512\", \"Drop-1024\", \"Drop-2048\"]\n",
    "\n",
    "# Match file names\n",
    "pattern = re.compile(r\"OneHotEncoder_(?P<fp>no_fp|morgan_fp_(?P<imp>zeros|nan)_(?P<size>\\d+))_seed_\\d+\\.csv\")\n",
    "\n",
    "# Read all data\n",
    "data = defaultdict(lambda: defaultdict(list))  # data[model][strategy] = list of LB WPCs\n",
    "\n",
    "for filepath in glob.glob(\"./*.csv\"):\n",
    "    filename = filepath.split(\"/\")[-1]\n",
    "    match = pattern.match(filename)\n",
    "    if not match:\n",
    "        continue\n",
    "\n",
    "    fp = match.group(\"fp\")\n",
    "    imp = match.group(\"imp\")\n",
    "    size = match.group(\"size\")\n",
    "\n",
    "    if fp == \"no_fp\":\n",
    "        strategy = \"No FP\"\n",
    "    elif imp == \"zeros\":\n",
    "        strategy = f\"Zero-{size}\"\n",
    "    elif imp == \"nan\":\n",
    "        strategy = f\"Drop-{size}\"\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(filepath)\n",
    "    for _, row in df.iterrows():\n",
    "        model = model_name_map[row[\"Model\"]]\n",
    "        lb_wpc = row[\"LB WPC\"]\n",
    "        data[model][strategy].append(lb_wpc)\n",
    "\n",
    "# Create LaTeX table\n",
    "header = r\"\"\"\\begin{table}[ht]\n",
    "\\centering\n",
    "\\footnotesize\n",
    "\\caption{\\textbf{LB WPC comparison with and without Morgan fingerprints using different imputation strategies.} Results are reported as mean (standard deviation) over 10 random seeds.}\n",
    "\\begin{tabular}{lccccccc}\n",
    "\\toprule\n",
    "Model & No FP & Zero-512 & Zero-1024 & Zero-2048 & Drop-512 & Drop-1024 & Drop-2048 \\\\\n",
    "\\midrule\n",
    "\"\"\"\n",
    "\n",
    "body = \"\"\n",
    "for model in model_order:\n",
    "    row_vals = []\n",
    "    for strat in strategies:\n",
    "        vals = data[model].get(strat, [])\n",
    "        if vals:\n",
    "            mean = pd.Series(vals).mean()\n",
    "            std = pd.Series(vals).std()\n",
    "            row_vals.append((mean, std))\n",
    "        else:\n",
    "            row_vals.append(None)\n",
    "\n",
    "    # Identify best mean\n",
    "    valid_means = [(i, val[0]) for i, val in enumerate(row_vals) if val is not None]\n",
    "    best_idx = max(valid_means, key=lambda x: x[1])[0] if valid_means else None\n",
    "\n",
    "    # Build row\n",
    "    row = [model]\n",
    "    for i, val in enumerate(row_vals):\n",
    "        if val is None:\n",
    "            row.append(\"-\")\n",
    "        else:\n",
    "            mean, std = val\n",
    "            formatted = f\"{mean:.3f} ({std:.3f})\"\n",
    "            if i == best_idx:\n",
    "                formatted = r\"\\textbf{\" + formatted + \"}\"\n",
    "            row.append(formatted)\n",
    "    body += \" & \".join(row) + r\" \\\\\" + \"\\n\"\n",
    "\n",
    "footer = r\"\"\"\\bottomrule\n",
    "\\end{tabular}\n",
    "\\end{table}\"\"\"\n",
    "\n",
    "# Output LaTeX table\n",
    "print(header + body + footer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cat_drug_synergy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
